# DSP final project

## 動機
通常在各個網路論壇中，如果想要找尋某個議題的討論文章，只能使用論壇給予的搜尋功能，但如果關鍵字下錯，甚至有些文章標題沒有打出關鍵字，則就沒有辦法找到所有想要的結果。
而因為課堂上有教到article summary的相關知識，讓我覺得可以往這個方向開發"以文搜文"的系統。然而就算是相同討論主題的文章也不太可能產生相同的summary，因此我退而使用tf-idf，想要找出每篇文章的關鍵詞，再透過比對關鍵詞的方式來找出相關主題的文章

雖然感覺蠻簡單的但我google"以文搜文"沒有看到什麼人或是網站有做這件事情，不知道是因為太簡單了還是成果不太好

## 設計
首先利用爬蟲程式爬取論壇的文章並進行整理(此處使用PTT八卦版之文章)，接著使用JieBa套件對每個文章都進行斷詞，然後計算這些文章的tf-idf。最後透過得到的tf-idf取得每個文章的關鍵詞。
進行檢索的時候也是把文章抓取下來後並斷詞，接著使用前面的td-idf檔案來取得關鍵詞，最後拿這些關鍵詞比較文章庫，取出比較相近的文章資訊。

### 流程圖如下：
![](https://i.imgur.com/m4CTadn.png)


## 紀錄
### 爬蟲
本範例是爬PTT的討論版(有測試過NTU版以及Gossip版)
本階段主要會遇到的問題除了爬蟲的語法之外，因為八卦版會限制18歲以上才能觀看，所以進入時會跳確認頁面，我們可藉由request時加入 "cookies={'over18': '1'}" 來避免這頁跳出來。

### 文章整理
雖然每篇文章都會出現的字(如"標題"、"日期"字樣)因tf-idf可以忽略，但仍有一些每篇文章都不一樣的內容(如網址、作者id)可能被誤判為關鍵詞，因此需要拿掉。
標題、作者id等因為出現地方固定，可以在爬蟲時就忽略掉，但因網址出現的地方不固定，而且作者也有可能在文章中留下網址(如貼圖連結，轉貼連結)，因此我利用以下regex來過濾掉文中所有網址
```python
    final = re.sub(r'https?:\/\/[\w.\/]*\B', '', final, flags=re.MULTILINE)
```


### tf-idf
如果直接使用JieBa來計算tf-idf會出現很奇怪的結果，因此我們必須要自己來產生所有詞的idf。
不過自己寫的idf會遇到一些問題，會有一些透明字元被辨認出來，但在JieBa載入idf時就會出錯，因此必須手動挑掉他，以下是我實驗時曾出現過的錯誤狀況(有進行預處理了但不確定能不能全部挑掉)
  1. 空白
  2. \n (在文件中是完全空白的一行)
  3. 有蠻多奇怪的空白 (在文件中只看的到機率)

### 關鍵詞比對
如果找出的關鍵詞組不錯的話，這部分就蠻容易的。
我的作法是將每篇文章的關鍵詞組與要檢索的關鍵詞組比對，看有幾個相同的關鍵詞，再輸出相同數量大於一個threshold的所有文章。

## 成果
(待補)

## Reference
- https://github.com/fxsjy/jieba
- https://stevenloria.com/tf-idf/
- https://www.wikiwand.com/zh-tw/Tf-idf
- https://atedev.wordpress.com/2007/11/23/%E6%AD%A3%E8%A6%8F%E8%A1%A8%E7%A4%BA%E5%BC%8F-regular-expression/
- 